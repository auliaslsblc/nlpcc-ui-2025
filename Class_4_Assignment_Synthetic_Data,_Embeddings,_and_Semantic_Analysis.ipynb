{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UioTNR7Acdjg"
      ],
      "authorship_tag": "ABX9TyPFs87/bBuyDE120ta4A5hZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auliaslsblc/nlpcc-ui-2025/blob/main/Class_4_Assignment_Synthetic_Data%2C_Embeddings%2C_and_Semantic_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis and Semantic Search on Coffeeshop Reviews Using OpenAI Embeddings**\n",
        "\n",
        "This project focuses on analyzing cafe customer reviews, starting by structuring a dataset of reviews with their corresponding topics and sentiment labels. Subsequently, each review is transformed into a numerical embedding vector using an OpenAI model to capture its semantic meaning. Finally, these embeddings are leveraged to build an intelligent search system capable of finding the most relevant reviews based on user queries, utilizing cosine similarity as the measure of semantic likeness."
      ],
      "metadata": {
        "id": "UioTNR7Acdjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrXgJ_ChcfP5",
        "outputId": "d511fa42-1bb6-43bc-99e8-1fe39d5ddac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- GANTI DENGAN PATH YANG SUDAH DIVERIFIKASI ---\n",
        "# Berdasarkan output os.listdir(), buat path yang benar di sini:\n",
        "# Contoh jika file ada di MyDrive:\n",
        "# path_ke_file = '/content/drive/MyDrive/drive/Topic_Label_Coffeeshop.csv'\n",
        "# Contoh jika file ada di subfolder 'FolderSaya' di MyDrive:\n",
        "# path_ke_file = '/content/drive/MyDrive/drive/Topic_Label_Coffeeshop.csv'\n",
        "path_ke_file = '/content/drive/MyDrive/drive/Topic_Label_Coffeeshop.csv'\n",
        "try:\n",
        "    df_ulasan = pd.read_csv(path_ke_file)\n",
        "    print(f\"DataFrame berhasil dimuat dari: {path_ke_file}\")\n",
        "    print(\"Jumlah baris dan kolom:\", df_ulasan.shape)\n",
        "    print(df_ulasan.head())\n",
        "    # ... sisa kode Anda ...\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File MASIH tidak ditemukan di path '{path_ke_file}'.\")\n",
        "    print(\"Mohon periksa kembali output dari os.listdir() dan pastikan path dan nama file 100% akurat, termasuk huruf besar/kecil dan spasi.\")\n",
        "except Exception as e:\n",
        "    print(f\"Terjadi kesalahan saat membaca CSV: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6LyzARc6ml",
        "outputId": "b8fa7df6-c5a5-4cb1-a1b6-aee77489dce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame berhasil dimuat dari: /content/drive/MyDrive/drive/Topic_Label_Coffeeshop.csv\n",
            "Jumlah baris dan kolom: (200, 3)\n",
            "                                         Teks Ulasan              Topik  \\\n",
            "0  Tempatnya bener-bener bikin betah! Dikelilingi...  Suasana dan Vibes   \n",
            "1  Vibesnya asri dan sejukcocok buat healing atau...  Suasana dan Vibes   \n",
            "2  Suka banget sama konsepnya yang hijauudaranya ...  Suasana dan Vibes   \n",
            "3  Suasana di sini tuh tenang bangetbikin pikiran...  Suasana dan Vibes   \n",
            "4  Kalau cari tempat ngopi yang adem dan rindangd...  Suasana dan Vibes   \n",
            "\n",
            "     Label  \n",
            "0  Positif  \n",
            "1  Positif  \n",
            "2  Positif  \n",
            "3  Positif  \n",
            "4  Positif  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Text Embedding Generation\n",
        "The goal of this step is to convert each \"Review Text\" from your synthetic dataset into a numerical embedding vector using the specified model."
      ],
      "metadata": {
        "id": "4YSzU9R_dGbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 1: Mengambil API Key dari Colab Secrets\n",
        "from google.colab import userdata\n",
        "import openai # Import openai di sini agar bisa langsung digunakan setelah key didapat\n",
        "\n",
        "try:\n",
        "    openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if not openai_api_key:\n",
        "        raise ValueError(\"API key 'OPENAI_API_KEY' tidak ditemukan di Colab Secrets.\")\n",
        "    print(\"OpenAI API Key berhasil diambil dari Colab Secrets.\")\n",
        "\n",
        "    # Inisialisasi OpenAI client di sini setelah API key berhasil didapatkan\n",
        "    client = openai.OpenAI(api_key=openai_api_key)\n",
        "    print(\"OpenAI client berhasil diinisialisasi.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Pastikan Anda sudah menambahkan API key Anda ke Colab Secrets dengan nama 'OPENAI_API_KEY' dan mengaktifkan 'Notebook access'.\")\n",
        "    client = None # Set client ke None jika gagal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XINXe41pjB3z",
        "outputId": "2adda1dd-ce8d-405b-8216-6d60892184de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API Key berhasil diambil dari Colab Secrets.\n",
            "OpenAI client berhasil diinisialisasi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 2: Instal Pustaka\n",
        "!pip install openai pandas tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqsiUIXwdJxx",
        "outputId": "231bd451-ce51-4768-88a8-d505e9eecc5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 3: Impor Pustaka Tambahan\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os # Meskipun key sudah di-handle, os bisa berguna untuk hal lain"
      ],
      "metadata": {
        "id": "62Jsxqlkipof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 4 (Opsi A): Unggah File CSV\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Silakan unggah file CSV Anda yang berisi 'Teks Ulasan'.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    file_name = next(iter(uploaded)) # Mengambil nama file pertama yang diunggah\n",
        "    print(f\"\\nFile '{file_name}' berhasil diunggah.\")\n",
        "    try:\n",
        "        df = pd.read_csv(file_name)\n",
        "        print(\"DataFrame berhasil dimuat.\")\n",
        "        print(\"Contoh data:\")\n",
        "        print(df.head())\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat memuat CSV ke DataFrame: {e}\")\n",
        "        df = None # Set df ke None jika gagal\n",
        "else:\n",
        "    print(\"Tidak ada file yang diunggah.\")\n",
        "    df = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "lqlDbclfjNi0",
        "outputId": "859f2523-579b-4deb-93a1-4dec1ebdfcf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silakan unggah file CSV Anda yang berisi 'Teks Ulasan'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-06d3455e-d0f8-4f86-b581-27e923c98b43\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-06d3455e-d0f8-4f86-b581-27e923c98b43\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Topic_Label_Coffeeshop.csv to Topic_Label_Coffeeshop.csv\n",
            "\n",
            "File 'Topic_Label_Coffeeshop.csv' berhasil diunggah.\n",
            "DataFrame berhasil dimuat.\n",
            "Contoh data:\n",
            "                                         Teks Ulasan              Topik  \\\n",
            "0  Tempatnya bener-bener bikin betah! Dikelilingi...  Suasana dan Vibes   \n",
            "1  Vibesnya asri dan sejukcocok buat healing atau...  Suasana dan Vibes   \n",
            "2  Suka banget sama konsepnya yang hijauudaranya ...  Suasana dan Vibes   \n",
            "3  Suasana di sini tuh tenang bangetbikin pikiran...  Suasana dan Vibes   \n",
            "4  Kalau cari tempat ngopi yang adem dan rindangd...  Suasana dan Vibes   \n",
            "\n",
            "     Label  \n",
            "0  Positif  \n",
            "1  Positif  \n",
            "2  Positif  \n",
            "3  Positif  \n",
            "4  Positif  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 5: Fungsi untuk Menghasilkan Embedding\n",
        "# Pilih model embedding OpenAI Anda (sesuaikan dengan instruksi kelas atau preferensi)\n",
        "MODEL_EMBEDDING = \"text-embedding-3-small\"  # Model efisien dan cukup baik\n",
        "# MODEL_EMBEDDING = \"text-embedding-ada-002\" # Model generasi sebelumnya yang juga populer\n",
        "\n",
        "def get_embeddings_openai_batch(texts_list, model=MODEL_EMBEDDING, batch_size=200):\n",
        "    \"\"\"\n",
        "    Menghasilkan embedding untuk daftar teks dalam batch menggunakan OpenAI API.\n",
        "    texts_list: list dari string teks.\n",
        "    model: nama model embedding OpenAI.\n",
        "    batch_size: jumlah teks yang dikirim per panggilan API.\n",
        "    \"\"\"\n",
        "    if client is None:\n",
        "        print(\"OpenAI client tidak diinisialisasi. Tidak dapat menghasilkan embedding.\")\n",
        "        return None\n",
        "    if not texts_list:\n",
        "        print(\"Daftar teks kosong, tidak ada embedding yang dihasilkan.\")\n",
        "        return []\n",
        "\n",
        "    all_embeddings = []\n",
        "    print(f\"Memulai pembuatan embedding untuk {len(texts_list)} teks dengan model '{model}' dan batch size {batch_size}...\")\n",
        "\n",
        "    for i in tqdm(range(0, len(texts_list), batch_size), desc=\"Memproses Batch Embedding\"):\n",
        "        batch_texts = texts_list[i:i + batch_size]\n",
        "        # Pastikan tidak ada teks None atau kosong murni, ganti dengan spasi jika ada\n",
        "        processed_batch = [str(text).strip() if text and str(text).strip() else \" \" for text in batch_texts]\n",
        "\n",
        "        try:\n",
        "            response = client.embeddings.create(\n",
        "                input=processed_batch,\n",
        "                model=model\n",
        "            )\n",
        "            embeddings_for_batch = [item.embedding for item in response.data]\n",
        "            all_embeddings.extend(embeddings_for_batch)\n",
        "        except Exception as e:\n",
        "            print(f\"Error pada batch {i//batch_size + 1}: {e}\")\n",
        "            # Tambahkan None untuk setiap item dalam batch yang gagal agar panjangnya tetap sesuai\n",
        "            all_embeddings.extend([None] * len(batch_texts))\n",
        "\n",
        "    print(f\"Selesai membuat embedding. Total embedding dihasilkan/dicoba: {len(all_embeddings)}\")\n",
        "    return all_embeddings"
      ],
      "metadata": {
        "id": "0Q_73SLkjTeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 6: Hasilkan Embedding dan Simpan\n",
        "if df is not None and 'Teks Ulasan' in df.columns:\n",
        "    print(f\"\\nMemulai proses embedding untuk kolom 'Teks Ulasan' ({len(df)} baris)...\")\n",
        "\n",
        "    # Pastikan kolom 'Teks Ulasan' adalah string dan tangani nilai NaN\n",
        "    df['Teks Ulasan'] = df['Teks Ulasan'].astype(str).fillna(\" \")\n",
        "    list_of_reviews = df['Teks Ulasan'].tolist()\n",
        "\n",
        "    # Hasilkan embedding\n",
        "    embeddings_hasil = get_embeddings_openai_batch(list_of_reviews)\n",
        "\n",
        "    if embeddings_hasil and len(embeddings_hasil) == len(df):\n",
        "        df['embedding_openai'] = embeddings_hasil\n",
        "        print(\"\\nKolom 'embedding_openai' berhasil ditambahkan ke DataFrame.\")\n",
        "\n",
        "        # Cek berapa banyak embedding yang berhasil (bukan None)\n",
        "        valid_embeddings_count = df['embedding_openai'].count() # count() pada series pandas mengabaikan None\n",
        "        print(f\"Jumlah embedding yang valid (non-None): {valid_embeddings_count} dari {len(df)} ulasan.\")\n",
        "        if valid_embeddings_count < len(df):\n",
        "            print(\"Beberapa embedding mungkin gagal dibuat (bernilai None). Periksa output error di atas.\")\n",
        "\n",
        "        print(\"\\nContoh data dengan embedding:\")\n",
        "        # Tampilkan hanya kolom relevan dan beberapa baris agar tidak terlalu panjang\n",
        "        print(df[['Teks Ulasan', 'Label', 'embedding_openai']].head())\n",
        "\n",
        "        # Simpan DataFrame yang sudah ada embeddingnya\n",
        "        # Format pickle lebih baik untuk menyimpan list/array dalam sel DataFrame\n",
        "        output_filename_pkl = 'dataset_dengan_embedding_openai.pkl'\n",
        "        try:\n",
        "            df.to_pickle(output_filename_pkl)\n",
        "            print(f\"\\nDataFrame dengan embedding berhasil disimpan sebagai '{output_filename_pkl}'.\")\n",
        "            # Anda bisa mengunduhnya dari Colab jika perlu:\n",
        "            # files.download(output_filename_pkl)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saat menyimpan DataFrame ke pickle: {e}\")\n",
        "\n",
        "    elif embeddings_hasil is None:\n",
        "        print(\"\\nProses embedding tidak menghasilkan apa-apa, kemungkinan karena client OpenAI tidak siap.\")\n",
        "    else:\n",
        "        print(\"\\nJumlah embedding yang dihasilkan tidak sesuai dengan jumlah baris DataFrame. Silakan periksa error.\")\n",
        "\n",
        "elif df is None:\n",
        "    print(\"\\nDataFrame 'df' belum dimuat. Silakan jalankan sel untuk memuat data terlebih dahulu.\")\n",
        "else:\n",
        "    print(\"\\nKolom 'Teks Ulasan' tidak ditemukan dalam DataFrame. Pastikan nama kolom sudah benar.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYoVmSn_jZOp",
        "outputId": "c1b960ee-c6ae-4958-bfa3-95c72c99b17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Memulai proses embedding untuk kolom 'Teks Ulasan' (200 baris)...\n",
            "Memulai pembuatan embedding untuk 200 teks dengan model 'text-embedding-3-small' dan batch size 200...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Memproses Batch Embedding: 100%|██████████| 1/1 [00:03<00:00,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selesai membuat embedding. Total embedding dihasilkan/dicoba: 200\n",
            "\n",
            "Kolom 'embedding_openai' berhasil ditambahkan ke DataFrame.\n",
            "Jumlah embedding yang valid (non-None): 200 dari 200 ulasan.\n",
            "\n",
            "Contoh data dengan embedding:\n",
            "                                         Teks Ulasan    Label  \\\n",
            "0  Tempatnya bener-bener bikin betah! Dikelilingi...  Positif   \n",
            "1  Vibesnya asri dan sejukcocok buat healing atau...  Positif   \n",
            "2  Suka banget sama konsepnya yang hijauudaranya ...  Positif   \n",
            "3  Suasana di sini tuh tenang bangetbikin pikiran...  Positif   \n",
            "4  Kalau cari tempat ngopi yang adem dan rindangd...  Positif   \n",
            "\n",
            "                                    embedding_openai  \n",
            "0  [0.011053933762013912, -0.00456699263304472, -...  \n",
            "1  [-0.014044753275811672, 0.005080667324364185, ...  \n",
            "2  [-0.018063683062791824, -0.023671826347708702,...  \n",
            "3  [0.05218210816383362, -0.011847035959362984, -...  \n",
            "4  [-0.008472133427858353, -0.005187409929931164,...  \n",
            "\n",
            "DataFrame dengan embedding berhasil disimpan sebagai 'dataset_dengan_embedding_openai.pkl'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 3: EMBEDDING ANALYSIS**\n",
        "Semantic search goal: build a system that can accept a text query from a user, then find and rank the reviews from your dataset that are most similar in meaning (semantics) to the query. Similarity is measured using cosine similarity between the query embedding and the embedding of each review in the dataset."
      ],
      "metadata": {
        "id": "YPDfT3Fljl5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 7: Instal Pustaka (jika ada yang belum)\n",
        "!pip install scikit-learn numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtJJ8jG7jpc9",
        "outputId": "d1b194de-f16b-47aa-92bc-b244246972b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 8: Impor Pustaka\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Pastikan client OpenAI dan MODEL_EMBEDDING dari sel sebelumnya sudah ada\n",
        "# import openai # jika belum diimpor di sesi ini\n",
        "# MODEL_EMBEDDING = \"text-embedding-3-small\" # atau model yang Anda gunakan"
      ],
      "metadata": {
        "id": "NSC7pz9MjxUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 9: Persiapkan Embedding dari DataFrame\n",
        "if 'df' not in locals() or df is None or 'embedding_openai' not in df.columns:\n",
        "    print(\"DataFrame 'df' atau kolom 'embedding_openai' tidak ditemukan. Mohon jalankan Tugas 2 terlebih dahulu.\")\n",
        "else:\n",
        "    # Hapus baris di mana embedding mungkin None (jika ada kegagalan parsial di Tugas 2)\n",
        "    df_filtered = df.dropna(subset=['embedding_openai']).copy() # Buat salinan untuk menghindari SettingWithCopyWarning\n",
        "\n",
        "    if df_filtered.empty:\n",
        "        print(\"Tidak ada data dengan embedding yang valid untuk diproses.\")\n",
        "    else:\n",
        "        # Konversi list embedding menjadi matriks NumPy\n",
        "        # Pastikan setiap elemen adalah list/array angka dan bukan string atau None\n",
        "        valid_embeddings_list = [emb for emb in df_filtered['embedding_openai'].tolist() if isinstance(emb, (list, np.ndarray))]\n",
        "\n",
        "        if not valid_embeddings_list:\n",
        "            print(\"Tidak ditemukan embedding yang valid dalam format list atau array NumPy.\")\n",
        "        else:\n",
        "            # Cek apakah semua embedding memiliki dimensi yang sama\n",
        "            first_embedding_dim = len(valid_embeddings_list[0])\n",
        "            if not all(len(emb) == first_embedding_dim for emb in valid_embeddings_list):\n",
        "                print(\"Dimensi embedding tidak konsisten. Pastikan semua embedding memiliki panjang yang sama.\")\n",
        "                # Anda mungkin perlu memfilter lebih lanjut atau memperbaiki data embedding Anda.\n",
        "            else:\n",
        "                document_embeddings = np.array(valid_embeddings_list)\n",
        "                print(f\"Matriks embedding dokumen berhasil dibuat dengan shape: {document_embeddings.shape}\")\n",
        "                # Simpan juga teks yang sesuai dengan embedding ini untuk ditampilkan\n",
        "                corresponding_texts = df_filtered['Teks Ulasan'].tolist()\n",
        "                corresponding_labels = df_filtered['Label'].tolist() # Jika ingin menampilkan label juga"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhk11V3pj0sv",
        "outputId": "9baae33b-3f0e-477f-fd02-d098bd7f0b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriks embedding dokumen berhasil dibuat dengan shape: (200, 1536)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 10: Fungsi untuk Mendapatkan Embedding Kueri\n",
        "def get_query_embedding(query_text, model=MODEL_EMBEDDING):\n",
        "    \"\"\"\n",
        "    Menghasilkan embedding untuk satu teks kueri.\n",
        "    \"\"\"\n",
        "    if client is None:\n",
        "        print(\"Client OpenAI tidak diinisialisasi.\")\n",
        "        return None\n",
        "    try:\n",
        "        # Ganti string kosong dengan spasi untuk menghindari error API\n",
        "        processed_query = query_text if query_text and query_text.strip() else \" \"\n",
        "        response = client.embeddings.create(\n",
        "            input=[processed_query], # Kirim sebagai list walau hanya satu item\n",
        "            model=model\n",
        "        )\n",
        "        return response.data[0].embedding\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat membuat embedding untuk kueri '{query_text}': {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "Gz3ypmeRj3TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 11: Fungsi Pencarian Semantik\n",
        "def semantic_search(query_text, top_n=5):\n",
        "    \"\"\"\n",
        "    Melakukan pencarian semantik dan mengembalikan top_n hasil yang paling mirip.\n",
        "    \"\"\"\n",
        "    if 'document_embeddings' not in globals() or document_embeddings is None or document_embeddings.size == 0:\n",
        "        print(\"Embedding dokumen tidak tersedia. Jalankan persiapan embedding terlebih dahulu.\")\n",
        "        return\n",
        "\n",
        "    query_embedding = get_query_embedding(query_text)\n",
        "    if query_embedding is None:\n",
        "        return\n",
        "\n",
        "    # Reshape query_embedding menjadi 2D array untuk cosine_similarity\n",
        "    query_embedding_2d = np.array(query_embedding).reshape(1, -1)\n",
        "\n",
        "    # Hitung cosine similarity\n",
        "    similarities = cosine_similarity(query_embedding_2d, document_embeddings)\n",
        "\n",
        "    # Dapatkan skor similarity untuk setiap dokumen (flatten array)\n",
        "    similarity_scores = similarities[0]\n",
        "\n",
        "    # Urutkan dokumen berdasarkan similarity (dari tertinggi ke terendah)\n",
        "    # argsort mengembalikan indeks, [::-1] membalik urutannya\n",
        "    sorted_indices = np.argsort(similarity_scores)[::-1]\n",
        "\n",
        "    print(f\"\\nHasil Pencarian Cerdas untuk kueri: '{query_text}' (Top {top_n}):\")\n",
        "    print(\"-------------------------------------------------------------\")\n",
        "    for i in range(min(top_n, len(sorted_indices))):\n",
        "        idx = sorted_indices[i]\n",
        "        print(f\"Peringkat {i+1}:\")\n",
        "        print(f\"  Teks   : {corresponding_texts[idx][:200]}...\") # Tampilkan 200 karakter pertama\n",
        "        print(f\"  Label  : {corresponding_labels[idx]}\") # Tampilkan label sintetis\n",
        "        print(f\"  Skor Similarity: {similarity_scores[idx]:.4f}\")\n",
        "        print(\"---\")"
      ],
      "metadata": {
        "id": "59sZBZJ-kDOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel 12: Demonstrasi Pencarian\n",
        "# Pastikan sel-sel sebelumnya (terutama Sel 9, 10, 11) sudah dijalankan dan 'document_embeddings' serta 'client' sudah siap.\n",
        "\n",
        "# Contoh Kueri:\n",
        "query1 = \"kopi yang rasanya kuat dan pahit\"\n",
        "semantic_search(query1, top_n=3)\n",
        "\n",
        "query2 = \"tempat ngopi yang tenang untuk kerja\"\n",
        "semantic_search(query2, top_n=3)\n",
        "\n",
        "query3 = \"pelayanan lama dan tidak ramah\"\n",
        "semantic_search(query3, top_n=3)\n",
        "\n",
        "query4 = \"harga mahal tidak sepadan\"\n",
        "semantic_search(query4, top_n=3)\n",
        "\n",
        "query5 = \"wifi lemot bikin kesal\"\n",
        "semantic_search(query5, top_n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8ssj_SokH_Y",
        "outputId": "10c04de4-400b-4479-bcc4-bc84dd25c480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hasil Pencarian Cerdas untuk kueri: 'kopi yang rasanya kuat dan pahit' (Top 3):\n",
            "-------------------------------------------------------------\n",
            "Peringkat 1:\n",
            "  Teks   : Kopi hitamnya terlalu pahit gosongnggak enjoyable....\n",
            "  Label  : Negatif\n",
            "  Skor Similarity: 0.6915\n",
            "---\n",
            "Peringkat 2:\n",
            "  Teks   : Harganya sebanding sama rasa kopi dan suasana yang didapat....\n",
            "  Label  : Positif\n",
            "  Skor Similarity: 0.6258\n",
            "---\n",
            "Peringkat 3:\n",
            "  Teks   : Rasa kopinya otentik dan berkesan....\n",
            "  Label  : Positif\n",
            "  Skor Similarity: 0.6148\n",
            "---\n",
            "\n",
            "Hasil Pencarian Cerdas untuk kueri: 'tempat ngopi yang tenang untuk kerja' (Top 3):\n",
            "-------------------------------------------------------------\n",
            "Peringkat 1:\n",
            "  Teks   : Kalau cari tempat ngopi yang adem dan rindangdi sini juaranya....\n",
            "  Label  : Positif\n",
            "  Skor Similarity: 0.6468\n",
            "---\n",
            "Peringkat 2:\n",
            "  Teks   : Nggak nyangka ada tempat sehijau dan setenang ini buat ngopi....\n",
            "  Label  : Positif\n",
            "  Skor Similarity: 0.6030\n",
            "---\n",
            "Peringkat 3:\n",
            "  Teks   : WiFi kencangcocok buat kerja atau nugas....\n",
            "  Label  : Positif\n",
            "  Skor Similarity: 0.5162\n",
            "---\n",
            "\n",
            "Hasil Pencarian Cerdas untuk kueri: 'pelayanan lama dan tidak ramah' (Top 3):\n",
            "-------------------------------------------------------------\n",
            "Peringkat 1:\n",
            "  Teks   : Pelayanannya lama bangetnunggu kopi aja setengah jam lebih....\n",
            "  Label  : Negatif\n",
            "  Skor Similarity: 0.5944\n",
            "---\n",
            "Peringkat 2:\n",
            "  Teks   : Pelayanannya ramah dan cepat tanggapbikin nyaman....\n",
            "  Label  : Positif\n",
            "  Skor Similarity: 0.5932\n",
            "---\n",
            "Peringkat 3:\n",
            "  Teks   : Pelayanannya pilih-pilihyang datang rombongan dilayani duluan....\n",
            "  Label  : Negatif\n",
            "  Skor Similarity: 0.5339\n",
            "---\n",
            "\n",
            "Hasil Pencarian Cerdas untuk kueri: 'harga mahal tidak sepadan' (Top 3):\n",
            "-------------------------------------------------------------\n",
            "Peringkat 1:\n",
            "  Teks   : Kualitasnya menurun tapi harganya tetap mahal....\n",
            "  Label  : Negatif\n",
            "  Skor Similarity: 0.5680\n",
            "---\n",
            "Peringkat 2:\n",
            "  Teks   : Kualitas kopinya nggak sebanding sama harganya yang lumayan....\n",
            "  Label  : Negatif\n",
            "  Skor Similarity: 0.5622\n",
            "---\n",
            "Peringkat 3:\n",
            "  Teks   : Nilai plusnya di suasana yang nggak bisa dibelijadi harga oke lah....\n",
            "  Label  : Positif\n",
            "  Skor Similarity: 0.5550\n",
            "---\n",
            "\n",
            "Hasil Pencarian Cerdas untuk kueri: 'wifi lemot bikin kesal' (Top 3):\n",
            "-------------------------------------------------------------\n",
            "Peringkat 1:\n",
            "  Teks   : WiFi-nya lemot bangetputus-putus terusnggak bisa buat kerja....\n",
            "  Label  : Negatif\n",
            "  Skor Similarity: 0.6757\n",
            "---\n",
            "Peringkat 2:\n",
            "  Teks   : WiFi kencangcocok buat kerja atau nugas....\n",
            "  Label  : Positif\n",
            "  Skor Similarity: 0.5090\n",
            "---\n",
            "Peringkat 3:\n",
            "  Teks   : Jaringan internetnya bisa diandalkan untuk kerja....\n",
            "  Label  : Positif\n",
            "  Skor Similarity: 0.4388\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQv7AOpPkMtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 4: API Key Management**\n",
        "An important aspect of working with cloud APIs is securely managing your API keys."
      ],
      "metadata": {
        "id": "NaVhmHSDkoiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sel untuk Pengaturan Aman API Key OpenAI\n",
        "from google.colab import userdata\n",
        "import os # Opsional, jika Anda ingin menyimpannya juga sebagai environment variable\n",
        "\n",
        "# Nama secret yang Anda gunakan di Colab Secrets\n",
        "NAMA_SECRET_OPENAI_KEY = 'OPENAI_API_KEY' # Ini adalah nama yang Anda konfirmasi\n",
        "\n",
        "try:\n",
        "    # Mengambil API Key OpenAI dari Colab Secrets\n",
        "    openai_api_key = userdata.get(NAMA_SECRET_OPENAI_KEY)\n",
        "\n",
        "    if openai_api_key:\n",
        "        print(f\"API Key '{NAMA_SECRET_OPENAI_KEY}' berhasil dimuat dari Colab Secrets.\")\n",
        "        # Anda bisa menggunakannya untuk konfigurasi API OpenAI, contoh:\n",
        "        # import openai\n",
        "        # openai.api_key = openai_api_key\n",
        "        # print(\"Konfigurasi API OpenAI dengan kunci yang dimuat berhasil.\")\n",
        "\n",
        "        # (Opsional) Menyimpan sebagai environment variable untuk sesi ini\n",
        "        # os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "        # print(f\"API Key juga telah diatur sebagai environment variable 'OPENAI_API_KEY' untuk sesi ini.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"❌ Gagal memuat API Key '{NAMA_SECRET_OPENAI_KEY}'.\")\n",
        "        print(\"Pastikan Anda telah menambahkan secret dengan nama yang benar ('OPENAI_API_KEY') dan mengaktifkan 'Notebook access' di panel Secrets.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Perhatikan baris di bawah ini, pastikan stringnya lengkap\n",
        "    print(f\"Terjadi kesalahan saat mencoba mengakses API Key '{NAMA_SECRET_OPENAI_KEY}': {e}\")\n",
        "    print(\"Pastikan panel 'Secrets' sudah dikonfigurasi dengan benar.\") # <-- PERBAIKAN DI SINI\n",
        "\n",
        "# PENTING: JANGAN PERNAH MENULISKAN API KEY ANDA SECARA LANGSUNG DI SINI\n",
        "# contoh_api_key_SALAH = \"sk-***********************************\" # <= JANGAN LAKUKAN INI!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmHr_b7Gkp1R",
        "outputId": "a21d32f5-5dd3-488f-e758-d93bcbe7693d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key 'OPENAI_API_KEY' berhasil dimuat dari Colab Secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secure API Key Handling Storing API keys securely is vital to prevent unauthorized access and misuse.\n",
        "\n",
        "Colab Secrets (Secure): This method is secure because your API key is not written directly in your notebook's code. It's stored separately by Colab and accessed via userdata.get(). This prevents accidental exposure if you share your notebook or commit it to version control, as the secret value itself remains hidden.\n",
        "\n",
        "Hardcoding API Keys (Bad Practice): Hardcoding (e.g., api_key = \"sk-...\" in your code) is bad because it directly embeds your secret key into the code. This makes it highly vulnerable to exposure if the code is shared, committed to Git/GitHub, or even just displayed. Once exposed, the key can be easily stolen and misused."
      ],
      "metadata": {
        "id": "sLvSWJSQkxBj"
      }
    }
  ]
}